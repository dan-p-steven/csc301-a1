Generative A1 Usage Statement:
We utilized generative AI (claude) to accelerate the developement of the Inter-Service Communication Service and the Workload Parser.
Specifically, we prompted the AI to generate the boilerplate code for the com.sun.net.httpserver.HttpServer setup and the java.net.HttpURLConnection logic.
This ensured we adherehed to the constraints of using standard Java libraries without explicitly requiring external HTTP clients.

While the AI provided a functional skeleton, we made significant manual modifications to ensure compatibility with the lab environment and assignment quirks.
The AI generate parser did not account for the specific formatting inconsistencies in the combinedWorkload.txt. 
We manually implemented logic to check the parts.length of the input string and handle dynamic argument shifting to prevent ArrayIndexOutOfBounds exceptions.

---

Shortcuts and Scalability:
ISCS:
For assignment 1, the service reads a single IP and port for the User and Product services from config.json, and forwards traffic 1 to 1.
It effectively acts as a pipe, copying the request method, headers, and body to the destination and relaying the response back.

The current implementation assumes a single instance of every backend service. In assignment 2, we expect to scale to around 10,000 users,
requiring multiple instances of the User and Product services to handle the load. A pass-through cannot distribute traffic amoung these multiple. 
It would bottleneck on a singular instance.

We will rewrite the ForwardHandler login in ISCS.java. Instead of loading a single ServerConfig object, the configuarate parser will need to
accept a list of availible IP/Port pairs. We will implement a round robin load balancing algorithm to rotate incoming requests sequentially
across these availible instances.

Workload Parser:
The current Workload Parser executes commands synchronously. It reads a line from the file, opens an HTTP connection, 
sends the request, and blocks (waits) until the full response is received before processing the next line.

Waiting for a complete HTTP round trip for every siungle command introduces major latency. In order to process a million commands
in under 4 minutes, sequential execution is mathematically impossible give standard network latency. 

We will refactor the parser to use Multi-threading. While strict ordering must be maintained for commands targeting the same
user_id or prodcut_id, commands for different entities are independant. We plan to implement a threrad poo to send non-conflicting requestsin parallel.

---

Reusable Code Analysis:
Despite the planned changes for scalability, the majoritty of our code remains usable for a2.

ISCS:
The current Workload Parser executes commands synchronously. It reads a line from the file, opens an HTTP connection, sends the request, 
and blocks (waits) until the full response is received before processing the next line.

JSON Logic:
The Gson serialization logic in the Workload Parser matches the API specification perfectly. 
This protocol does not change between assignments, so the payload generation code is 100% reusable.